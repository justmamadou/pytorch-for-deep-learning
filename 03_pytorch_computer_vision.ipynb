{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Computer Vision"
      ],
      "metadata": {
        "id": "jl-_TPdJ3FSJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Computer vision libraries in PyTorch\n",
        "\n",
        "* `torchvision` - base domain library for PyTorch computer vision\n",
        "* `torchvision.datasets` - get datasets\n",
        "* `torchvision.transforms` - apply transformation to image\n",
        "* `torchvision.models` - get pretrained computer vision models\n",
        "* `torchvision.utils.data.Dataset` - Base dataset class for PyTorch\n",
        "* `torchvision.utils.data.DataLoader` - create a Python iterable over a dataset"
      ],
      "metadata": {
        "id": "3PwoMy744ej8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ],
      "metadata": {
        "id": "Uq_1Rgun4acW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "jjq_tIrXnXUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Getting a dataset\n",
        "\n",
        "The dataseyt we'll be using is FashionMNIST from torchvision.datasets"
      ],
      "metadata": {
        "id": "1f_u6BiE6hdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup training data\n",
        "from torchvision import datasets\n",
        "train_data = datasets.FashionMNIST(\n",
        "    root=\"data\", # where to download data to ?\n",
        "    train=True, # do we want the training data\n",
        "    download=True, # do we want to download yes/nnn\n",
        "    transform=torchvision.transforms.ToTensor(), # how do we want to transform the data ?\n",
        "    target_transform=None # how do we want to transform the labels/target\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\", # where to download data to ?\n",
        "    train=False, # do we want the training data\n",
        "    download=True, # do we want to download yes/non\n",
        "    transform=torchvision.transforms.ToTensor(), # how do we want to transform the data ?\n",
        "    target_transform=None # how do we want to transform the labels/target\n",
        ")"
      ],
      "metadata": {
        "id": "d7b4RRGe47og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "id": "OMEzGT6T74U-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_data[0]\n",
        "image, label"
      ],
      "metadata": {
        "id": "LiDnGB7t77rf",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes_names = train_data.classes\n",
        "classes_names"
      ],
      "metadata": {
        "id": "plNR4-0t8Y8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_to_idx = train_data.class_to_idx\n",
        "class_to_idx"
      ],
      "metadata": {
        "id": "_BLPqTei8s5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.targets"
      ],
      "metadata": {
        "id": "AAuxpMsn8y4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Check the input and output shape"
      ],
      "metadata": {
        "id": "nxMCmqTS9hqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the shape of our image\n",
        "print(f\"Image shape: {image.shape} -> [color_channels, height, width]\")\n",
        "print(f\"Image label: {classes_names[label]}\")"
      ],
      "metadata": {
        "id": "Qx1EffFx82c3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Visualizing our data"
      ],
      "metadata": {
        "id": "tPNuzOCZ-icQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image, label = train_data[0]\n",
        "print(f\"Image shape: {image.shape}\")\n",
        "plt.imshow(image.squeeze())\n",
        "plt.title(label);\n"
      ],
      "metadata": {
        "id": "gqHQZHDF9StG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(image.squeeze(), cmap=\"grey\")\n",
        "plt.title(classes_names[label]);\n",
        "plt.axis(False)"
      ],
      "metadata": {
        "id": "11r0EPKT-4gJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot more images\n",
        "torch.manual_seed(42)\n",
        "fig = plt.figure(figsize=(9,9))\n",
        "rows, cols = 4, 4\n",
        "for i in range(1, rows*cols+1):\n",
        "  random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
        "  img, label = train_data[random_idx]\n",
        "  fig.add_subplot(rows, cols, i)\n",
        "  plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "  plt.title(classes_names[label])\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "qGFyA5z2_V-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data"
      ],
      "metadata": {
        "id": "6oKIwCWsA1O1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Prepare DataLoader\n",
        "\n",
        "Right now, our data is in the form of PyTorch Datasets.\n",
        "\n",
        "DataLoader will turn the datasets to python iterable"
      ],
      "metadata": {
        "id": "3sZPTJAhCyYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Setupe the batch size hyperparameter\n",
        "BATCH_SIZE=32\n",
        "train_dataloader = DataLoader(dataset=train_data,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              shuffle=True)\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_data,\n",
        "                             batch_size=BATCH_SIZE,\n",
        "                             shuffle=False)\n",
        "\n",
        "train_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "mz6A3c1DCxKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "22EZJ4CstHpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's check out what we've created\n",
        "print(f\"DataLoaders: {train_dataloader, test_dataloader}\")\n",
        "print(f\"Lenght of train_dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
        "print(f\"Lenght of test_dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")"
      ],
      "metadata": {
        "id": "G6dnyLT0D99C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out what's inside the training dataloader\n",
        "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
        "train_features_batch.shape, train_labels_batch.shape"
      ],
      "metadata": {
        "id": "TKPOzZudEeQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show a sample\n",
        "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
        "img, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
        "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.title(classes_names[label])\n",
        "plt.axis(False)\n",
        "print(f\"Image size: {img.shape}\")\n",
        "print(f\"Label: {label}, label size: {label.shape}\")"
      ],
      "metadata": {
        "id": "Kaj7-nhADtXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Model 0: Build a baseline model"
      ],
      "metadata": {
        "id": "ZaebCcX8FcDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a flatten layer\n",
        "flatten_model = nn.Flatten()\n",
        "\n",
        "# Get a single sample\n",
        "x = train_features_batch[0]\n",
        "\n",
        "# Flatten the sample\n",
        "output = flatten_model(x) # perform forwards pass\n",
        "\n",
        "# Print\n",
        "print(f\"Shape before flattened: {x.shape}\")\n",
        "print(f\"Shape after flattened: {output.shape}\")"
      ],
      "metadata": {
        "id": "eHOOpcLTEyxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class FashionMNISTModelV0(nn.Module):\n",
        "  def __init__(self,\n",
        "               input_shape: int,\n",
        "               hidden_units: int,\n",
        "               output_shape: int) :\n",
        "    super().__init__()\n",
        "    self.layer_stack = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=input_shape,\n",
        "                  out_features=hidden_units),\n",
        "        nn.Linear(in_features=hidden_units,\n",
        "                  out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layer_stack(x)\n"
      ],
      "metadata": {
        "id": "0hxa4WhHIIhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0 = FashionMNISTModelV0(\n",
        "    input_shape=28*28,\n",
        "    hidden_units=10,\n",
        "    output_shape=len(classes_names)\n",
        ").to(\"cpu\")\n",
        "\n",
        "model_0"
      ],
      "metadata": {
        "id": "-liGV4VFNIiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_x =  torch.rand([1, 1, 28, 28])\n",
        "model_0(dummy_x)"
      ],
      "metadata": {
        "id": "Au86SQNwNWZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1. Setup loss, optimizer and evaluation metrics\n",
        "\n",
        "* Loss function - since we're working with multi-class data, our loss function will be `nn.CrossEntropyLoss`\n",
        "* Optimizer - our optimizer `torch.optim.SGD()`\n",
        "* Evaluation metrics - sincce we're working with classification, our evaluation metris will be `accuracy`"
      ],
      "metadata": {
        "id": "Bu-yeY3POoLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "if Path(\"helper_function.py\").is_file():\n",
        "  print(\"File already exists\")\n",
        "else:\n",
        "  print(\"Downloading helper_functions.py\")\n",
        "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/refs/heads/main/helper_functions.py\")\n",
        "  with open(\"helper_functions.py\", \"wb\") as f:\n",
        "    f.write(request.content)"
      ],
      "metadata": {
        "id": "eygeksRHNh8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import accuracy metric\n",
        "from helper_functions import accuracy_fn\n",
        "\n",
        "# Setup loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(),\n",
        "                            lr=0.1)"
      ],
      "metadata": {
        "id": "6Lc1cCwjQCtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Creating a function to titme pir experiments\n",
        "\n",
        "MAchine learning is very experimental\n",
        "\n",
        "Two of the main things you'll often want to track are:\n",
        "1. Model's performance (loss and accuracy values etc)\n",
        "2. How fast it runs"
      ],
      "metadata": {
        "id": "0mC3iXCVRywv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "def print_train_time(start: float,\n",
        "                     end: float,\n",
        "                     device: torch.device = None):\n",
        "  \"\"\"Prints difference between start and end time.\"\"\"\n",
        "  total_time = end - start\n",
        "  print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
        "  return total_time"
      ],
      "metadata": {
        "id": "d8vVJV6fQJZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from time import sleep\n",
        "start_time = timer()\n",
        "sleep(10)\n",
        "end_time = timer()\n",
        "print_train_time(start=start_time, end=end_time, device=\"cpu\")"
      ],
      "metadata": {
        "id": "r1uTrnJbStMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Creating a training loop and training a model on batches of data...\n",
        "\n",
        "1. Loop through epochs\n",
        "2. Loop through training batches, perform training steps, calculate the train loss *per batch*\n",
        "3. Loop through testing batches, perform testing steps, calculate the test loss per batch\n",
        "4. Print out what's happening\n",
        "5. Time it all (for fun)\n",
        "\n",
        "Hightlight that the optimizer will update a model's parameters once per batch rather than once per epoch..."
      ],
      "metadata": {
        "id": "CT49Hc0ybeOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tqdm for progress bar\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Set the seed and start the timer\n",
        "torch.manual_seed(42)\n",
        "train_time_start_on_cpu = timer()\n",
        "\n",
        "# Set the number of epochs(small for faster training time)\n",
        "epochs = 3\n",
        "\n",
        "# Creating train and test loop\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch}\\n-----\")\n",
        "  ### Training\n",
        "  train_loss = 0\n",
        "  # Add a loop to loop through the training batches\n",
        "  for batch, (X,y) in enumerate(train_dataloader):\n",
        "    model_0.train()\n",
        "    # 1. Forward pass\n",
        "    y_pred = model_0(X)\n",
        "\n",
        "    # 2. Calculate the loss (per batches)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss+= loss # accumulate train loss\n",
        "\n",
        "    # 3. Zero_grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Backpropagation\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Optimizer Step\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print out what's happening\n",
        "    if batch % 400 == 0:\n",
        "      print(f\"Looked at: {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
        "\n",
        "  # Divide total train loss by lenght of train dataloader\n",
        "  train_loss /= len(train_dataloader)\n",
        "\n",
        "  ### Testing\n",
        "  test_loss, test_acc = 0, 0\n",
        "  model_0.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X_test, y_test in test_dataloader:\n",
        "      # 1. Forward pass\n",
        "      test_pred = model_0(X_test)\n",
        "\n",
        "      # 2. Calculate the loss (accumulatively)\n",
        "      test_loss += loss_fn(test_pred, y_test)\n",
        "\n",
        "      # 3. Calculate accuracy\n",
        "      test_acc += accuracy_fn(y_true=y_test, y_pred=test_pred.argmax(dim=1))\n",
        "\n",
        "    # Calculate the test loss average per batch\n",
        "    test_loss /= len(test_dataloader)\n",
        "\n",
        "    # Calculate the test acc average per batch\n",
        "    test_acc /= len(test_dataloader)\n",
        "\n",
        "  # Print out what's happening\n",
        "  print(f\"\\nTrain loss: {train_loss:.4f} | Test loss: {test_loss:.4f} | Test acc: {test_acc:.4f}%\")\n",
        "\n",
        "# Calculate training time\n",
        "train_time_end_on_cpu = timer()\n",
        "total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu,\n",
        "                                            end=train_time_end_on_cpu,\n",
        "                                            device=str(next(model_0.parameters()).device))\n",
        "\n"
      ],
      "metadata": {
        "id": "J5T89A0fTB-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Make predictions and get Model 0 results\n"
      ],
      "metadata": {
        "id": "F5WLX_2FloSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "def eval_model(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               accuracy_fn):\n",
        "  \"\"\"Returns a dictionary containg the results of model predicting on data_loader\"\"\"\n",
        "  loss, acc = 0,0\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X, y in tqdm(data_loader):\n",
        "      # Put data on device\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      # Make predictions\n",
        "      y_pred = model(X)\n",
        "\n",
        "      # Accumulate the loss and acc values per batch\n",
        "      loss += loss_fn(y_pred, y)\n",
        "      acc += accuracy_fn(y_true=y,\n",
        "                         y_pred=y_pred.argmax(dim=1))\n",
        "\n",
        "    # scale loss and acc to find the average loss/acc per batch\n",
        "    loss /= len(data_loader)\n",
        "    acc /= len(data_loader)\n",
        "\n",
        "    return {\n",
        "        \"model_name\": model.__class__.__name__,\n",
        "        \"model_loss\": loss.item(),\n",
        "        \"model_acc\": acc\n",
        "    }\n"
      ],
      "metadata": {
        "id": "tu9xKGVKkqV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model 0 results on test dataset\n",
        "model_0_results = eval_model(model=model_0.to(device),\n",
        "                             data_loader=test_dataloader,\n",
        "                             loss_fn=loss_fn,\n",
        "                             accuracy_fn=accuracy_fn)\n",
        "\n",
        "model_0_results"
      ],
      "metadata": {
        "id": "_Fy8OhCNuZgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Setup device agnostic-code (for using a GPU if there is one)"
      ],
      "metadata": {
        "id": "NSUZWtF_nlNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_01 = FashionMNISTModelV0(\n",
        "    input_shape=28*28,\n",
        "    hidden_units=10,\n",
        "    output_shape=len(classes_names)\n",
        ").to(device)\n",
        "\n",
        "model_01"
      ],
      "metadata": {
        "id": "Y0UBCMqan69D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(model_01.parameters()).device"
      ],
      "metadata": {
        "id": "JkFW-teZukQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1 Setup loss and optimize"
      ],
      "metadata": {
        "id": "l78_iZDgpS-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import accuracy_fn\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_01.parameters(),\n",
        "                            lr=0.1)\n"
      ],
      "metadata": {
        "id": "Z_A-BLIIpXUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2 Creating a training and testing loop"
      ],
      "metadata": {
        "id": "ELQS9TC2pxL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tqdm for progress bar\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Set the seed and start the timer\n",
        "torch.manual_seed(42)\n",
        "train_time_start_on_gpu = timer()\n",
        "\n",
        "\n",
        "# Set the number of epochs(small for faster training time)\n",
        "epochs = 3\n",
        "\n",
        "# training loop\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch}\\n-------\")\n",
        "  for batch, (X_train, y_train) in enumerate(train_dataloader):\n",
        "    # Put data on device\n",
        "    X_train, y_train = X_train.to(device), y_train.to(device)\n",
        "    ### Training\n",
        "    train_loss = 0\n",
        "    model_01.train()\n",
        "\n",
        "    # 1. forward pass\n",
        "    y_pred = model_01(X_train)\n",
        "\n",
        "    # 2. Calculate the loss (per batchs)\n",
        "    loss = loss_fn(y_pred, y_train)\n",
        "    train_loss += loss\n",
        "\n",
        "    # 3. Optimizer zero_grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. loss backward (backpropagation)\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 400 == 0:\n",
        "      print(f\"Looked at: {batch * len(X_train)}/{len(train_dataloader.dataset)} samples\")\n",
        "\n",
        "  # Calculate the training loss\n",
        "  train_loss /= len(X_train)\n",
        "\n",
        "  ### Testing\n",
        "  test_loss, test_acc = 0, 0\n",
        "  model_01.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X_test, y_test in test_dataloader:\n",
        "      # Put data on device\n",
        "      X_test, y_test = X_test.to(device), y_test.to(device)\n",
        "\n",
        "      # 1. Forward pass\n",
        "      test_pred = model_01(X_test)\n",
        "\n",
        "      # 2. Calculate the loss (accumulatively)\n",
        "      test_loss += loss_fn(test_pred, y_test)\n",
        "\n",
        "      # 3. Calculate accuracy\n",
        "      test_acc += accuracy_fn(y_true=y_test, y_pred=test_pred.argmax(dim=1))\n",
        "\n",
        "    # Calculate the test loss average per batch\n",
        "    test_loss /= len(test_dataloader)\n",
        "\n",
        "    # Calculate the test acc average per batch\n",
        "    test_acc /= len(test_dataloader)\n",
        "\n",
        "  # Print out what's happening\n",
        "  print(f\"\\nTrain loss: {train_loss:.4f} | Test loss: {test_loss:.4f} | Test acc: {test_acc:.4f}\")\n",
        "\n",
        "# Calculate training time\n",
        "train_time_end_on_gpu = timer()\n",
        "total_train_time_model_1 = print_train_time(start=train_time_start_on_gpu,\n",
        "                                            end=train_time_end_on_gpu,\n",
        "                                            device=str(next(model_01.parameters()).device))"
      ],
      "metadata": {
        "id": "GFMjUdCDpi67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3 Evaluate model"
      ],
      "metadata": {
        "id": "wgTreksJuMjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model 0 results on test dataset\n",
        "model_01_results = eval_model(model=model_01,\n",
        "                             data_loader=test_dataloader,\n",
        "                             loss_fn=loss_fn,\n",
        "                             accuracy_fn=accuracy_fn)\n",
        "\n",
        "model_01_results"
      ],
      "metadata": {
        "id": "L3EHnKRVtutH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Model 1: Building a better model with non-linearity"
      ],
      "metadata": {
        "id": "jOS8fu6NOcRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.activation import ReLU\n",
        "from torch.nn.modules.linear import Linear\n",
        "# Create a model with non-linear and linear layers\n",
        "class FashionMNISTModelV1(nn.Module):\n",
        "  def __init__(self,\n",
        "               input_shape: int,\n",
        "               hidden_units: int,\n",
        "               output_shape: int\n",
        "               ) :\n",
        "    super().__init__()\n",
        "    self.layer_stack = nn.Sequential(\n",
        "        nn.Flatten(), # flatten inputs into a single vector\n",
        "        nn.Linear(in_features=input_shape,\n",
        "                  out_features=hidden_units),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=hidden_units,\n",
        "                  out_features=output_shape),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "    return self.layer_stack(x)"
      ],
      "metadata": {
        "id": "Vn9r4BsPuSyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of model_1\n",
        "torch.manual_seed(42)\n",
        "model_1 = FashionMNISTModelV1(\n",
        "    input_shape=784,\n",
        "    hidden_units=10,\n",
        "    output_shape=len(classes_names)\n",
        ").to(device)\n",
        "\n",
        "next(model_1.parameters()).device"
      ],
      "metadata": {
        "id": "m8RgF3YLQ1tY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1 Create a loss function and optimizer"
      ],
      "metadata": {
        "id": "L0vWn7fkRmxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_1.parameters(), lr=0.1)\n",
        "from helper_functions import accuracy_fn"
      ],
      "metadata": {
        "id": "n2KKm3bfRi13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2 Functionizing training and evaluation loop"
      ],
      "metadata": {
        "id": "kQbxbntRUxu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.nn.Module,\n",
        "               accuracy_fn,\n",
        "               device: torch.device = device):\n",
        "  \"\"\"Perform model training\"\"\"\n",
        "  train_loss, train_acc = 0, 0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "\n",
        "  for batch, (X_train, y_train) in enumerate(data_loader):\n",
        "    # Put data on target device\n",
        "    X_train, y_train = X_train.to(device), y_train.to(device)\n",
        "\n",
        "    # 1. Forward pass\n",
        "    y_pred = model(X_train)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss= loss_fn(y_pred, y_train)\n",
        "    train_loss += loss\n",
        "    train_acc += accuracy_fn(y_true=y_train,\n",
        "                             y_pred=y_pred.argmax(dim=1))\n",
        "\n",
        "    # Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # loss backward\n",
        "    loss.backward()\n",
        "\n",
        "    # Optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "  # Calculate the training loss\n",
        "  train_loss /= len(data_loader)\n",
        "  train_acc /= len(data_loader)\n",
        "  print(f\"\\nTrain loss: {train_loss:.4f} | Train acc: {train_acc:.4f}%\")"
      ],
      "metadata": {
        "id": "E6wYsBrGShGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step(model: torch.nn.Module,\n",
        "              data_loader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              accuracy_fn,\n",
        "              device: torch.device = device):\n",
        "  ### Testing\n",
        "  test_loss, test_acc = 0, 0\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X_test, y_test in data_loader:\n",
        "      # Put data on device\n",
        "      X_test, y_test = X_test.to(device), y_test.to(device)\n",
        "\n",
        "      # 1. Forward pass\n",
        "      test_pred = model(X_test)\n",
        "\n",
        "      # 2. Calculate the loss (accumulatively)\n",
        "      test_loss += loss_fn(test_pred, y_test)\n",
        "\n",
        "      # 3. Calculate accuracy\n",
        "      test_acc += accuracy_fn(y_true=y_test, y_pred=test_pred.argmax(dim=1))\n",
        "\n",
        "    # Calculate the test loss average per batch\n",
        "    test_loss /= len(data_loader)\n",
        "\n",
        "    # Calculate the test acc average per batch\n",
        "    test_acc /= len(data_loader)\n",
        "\n",
        "    # Print out what's happening\n",
        "    print(f\"\\nTest loss: {test_loss:.2f} | Test acc: {test_acc:.2f}%\")"
      ],
      "metadata": {
        "id": "DttDbAvJXDXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import tqdm for progress bar\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Set the seed and start the timer\n",
        "torch.manual_seed(42)\n",
        "train_time_start_on_gpu = timer()\n",
        "\n",
        "# Set the number of epochs(small for faster training time)\n",
        "epochs = 3\n",
        "\n",
        "# training loop\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch}\\n-------\")\n",
        "\n",
        "  train_step(model=model_1,\n",
        "             data_loader=train_dataloader,\n",
        "             loss_fn=loss_fn,\n",
        "             optimizer=optimizer,\n",
        "             accuracy_fn=accuracy_fn)\n",
        "\n",
        "  test_step(model=model_1,\n",
        "            data_loader=test_dataloader,\n",
        "            loss_fn=loss_fn,\n",
        "            accuracy_fn=accuracy_fn)\n",
        "\n",
        "# Calculate training time\n",
        "train_time_end_on_gpu = timer()\n",
        "total_train_time_model_1 = print_train_time(start=train_time_start_on_gpu,\n",
        "                                            end=train_time_end_on_gpu,\n",
        "                                            device=str(next(model_1.parameters()).device))"
      ],
      "metadata": {
        "id": "9jYuIwpwZWnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get model_1 results dictionary\n",
        "model_1_results = eval_model(model=model_1,\n",
        "                             data_loader=test_dataloader,\n",
        "                             loss_fn=loss_fn,\n",
        "                             accuracy_fn=accuracy_fn\n",
        "                             )\n",
        "\n",
        "model_1_results"
      ],
      "metadata": {
        "id": "R7YWERpgc7lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2: Building a Convolutional Neural Network (CNN)\n",
        "\n",
        "code the tinyVGG in the CNN explainer website\n",
        "\n"
      ],
      "metadata": {
        "id": "JAwCfoZYUGs5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a convolutional neueral network\n",
        "class FashionMNISTModelV2(nn.Module):\n",
        "  \"\"\"\n",
        "  Model architecture that replicates the TinyVGG\n",
        "  model from CNN explainer website.\n",
        "  \"\"\"\n",
        "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "    super().__init__()\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*7*7, # there's a trick to calculate this\n",
        "                  out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv_block_1(x)\n",
        "    #print(f\"Output shape of conv_block_1: {x.shape}\")\n",
        "    x = self.conv_block_2(x)\n",
        "    #print(f\"Output shape of conv_block_2: {x.shape}\")\n",
        "    x = self.classifier(x)\n",
        "    #print(f\"Output shape of classifier: {x.shape}\")\n",
        "    return x"
      ],
      "metadata": {
        "id": "5DQDIeBsdW7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model_2 = FashionMNISTModelV2(input_shape=1,\n",
        "                              hidden_units=10,\n",
        "                              output_shape=len(classes_names)\n",
        "                              ).to(device)"
      ],
      "metadata": {
        "id": "BtugueiObRIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.state_dict()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "khOCrBU_ds4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rand_image_tensor = torch.randn(size=(1, 28, 28))\n",
        "rand_image_tensor.shape"
      ],
      "metadata": {
        "id": "nMMiW5DrzGtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2(rand_image_tensor.unsqueeze(dim=0).to(device))"
      ],
      "metadata": {
        "id": "YrAIZffqzlQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.1 Stepping through `nn.conv2d`"
      ],
      "metadata": {
        "id": "amOyzAMJc7vO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "# Create a batch of images\n",
        "images = torch.randn(size=(32,3,64,64))\n",
        "test_image = images[0]\n",
        "\n",
        "print(f\"Image batch shape: {images.shape}\")\n",
        "print(f\"Single image shape: {test_image.shape}\")\n",
        "print(f\"Test image:\\n {test_image}\")"
      ],
      "metadata": {
        "id": "tEC8w4O4dCZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a single conv2d layer\n",
        "conv_layer = nn.Conv2d(in_channels=3, # nbr of colors channels\n",
        "                       out_channels=10, # nbr of hidden units\n",
        "                       kernel_size=(3,3),\n",
        "                       stride=1,\n",
        "                       padding=1\n",
        "                       )\n",
        "\n",
        "# Pass the data through the convolutional layer\n",
        "conv_output = conv_layer(test_image)\n",
        "conv_output"
      ],
      "metadata": {
        "id": "6rGM47yNd-kP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image.shape"
      ],
      "metadata": {
        "id": "blDYbkpqf_Yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_output.shape"
      ],
      "metadata": {
        "id": "vVsURAeUgJdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2 Steppping through `nn.MaxPool2d()`"
      ],
      "metadata": {
        "id": "9uxffTcig8Up"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Test image original shape: {test_image.shape}\")\n",
        "#print(f\"Test image with unsqueezed dimension: {test_image.unsqueeze(dim=0).shape}\")\n",
        "\n",
        "# Create a sample nn.maxPool2d layer\n",
        "max_pool_layer = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "# Pass data through just the conv_layer\n",
        "test_image_through_conv = conv_layer(test_image)\n",
        "print(f\"Shape after going through conv_layer(): {test_image_through_conv.shape}\")\n",
        "\n",
        "# Pass data through the max pool layer\n",
        "test_image_through_conv_and_max_pool = max_pool_layer(test_image_through_conv)\n",
        "print(f\"Shape after going through conv_layer() and max_pool_layer(): {test_image_through_conv_and_max_pool.shape}\")\n"
      ],
      "metadata": {
        "id": "vQWtTx5XgLn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.3 Setup a loss function and optimizer"
      ],
      "metadata": {
        "id": "WNE4iyDN1DW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup loss function/eval metrics/optimizer\n",
        "from helper_functions import accuracy_fn\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_2.parameters(), lr=0.1)\n"
      ],
      "metadata": {
        "id": "T23gXgvOhcPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.4 Training and testing `model_2` using our training and test functions"
      ],
      "metadata": {
        "id": "8odxBe5s1lUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Mesure time\n",
        "from timeit import default_timer as timer\n",
        "train_time_start_model_2 = timer()\n",
        "\n",
        "# Train and test model\n",
        "epochs = 3\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch}\\n---------\")\n",
        "  train_step(model=model_2,\n",
        "             data_loader=train_dataloader,\n",
        "             loss_fn=loss_fn,\n",
        "             optimizer=optimizer,\n",
        "             accuracy_fn=accuracy_fn,\n",
        "             device=device)\n",
        "  test_step(model=model_2,\n",
        "            data_loader=test_dataloader,\n",
        "            loss_fn=loss_fn,\n",
        "            accuracy_fn=accuracy_fn,\n",
        "            device=device)\n",
        "\n",
        "train_time_end_model_2 = timer()\n",
        "total_train_time_model_2 = print_train_time(start=train_time_start_model_2,\n",
        "                                            end=train_time_end_model_2,\n",
        "                                            device=device)"
      ],
      "metadata": {
        "id": "pQTg0YNx1iGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get model_2 results dictionary\n",
        "model_2_results = eval_model(model=model_2,\n",
        "                             data_loader=test_dataloader,\n",
        "                             loss_fn=loss_fn,\n",
        "                             accuracy_fn=accuracy_fn\n",
        "                             )\n",
        "\n",
        "model_2_results"
      ],
      "metadata": {
        "id": "_VOCyaWO3C9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Compare model results and training time"
      ],
      "metadata": {
        "id": "DdRHNt0I6Dt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "compare_results = pd.DataFrame([model_0_results,\n",
        "                                model_1_results,\n",
        "                                model_2_results])\n",
        "compare_results"
      ],
      "metadata": {
        "id": "JRTc1IwD5gFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add training time to results comparison\n",
        "compare_results[\"training_time\"] = [total_train_time_model_0,\n",
        "                                    total_train_time_model_1,\n",
        "                                    total_train_time_model_2]\n",
        "compare_results"
      ],
      "metadata": {
        "id": "u4jX_GGK6Vxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize our model results\n",
        "compare_results.set_index(\"model_name\")[\"model_acc\"].plot(kind=\"barh\")\n",
        "plt.xlabel(\"accuracy (%)\")\n",
        "plt.ylabel(\"model\")"
      ],
      "metadata": {
        "id": "6owPTXSX6_GR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Make and evaluate random predictions with best model"
      ],
      "metadata": {
        "id": "LT02JKRQ8AjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(model: torch.nn.Module,\n",
        "                     data: list,\n",
        "                     device: torch.device = device):\n",
        "  pred_probs = []\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for sample in data:\n",
        "      sample = torch.unsqueeze(sample, dim=0).to(device)\n",
        "\n",
        "      # Forward pass (model outputs raw logits)\n",
        "      pred_logit = model(sample)\n",
        "\n",
        "      # Get prediction probability (logit -> prediction probability)\n",
        "      pred_prob = torch.softmax(pred_logit.squeeze(), dim=0)\n",
        "\n",
        "      # Get pred_prob off the GPU for further calculations\n",
        "      pred_probs.append(pred_prob.cpu())\n",
        "\n",
        "  return torch.stack(pred_probs)\n",
        "\n"
      ],
      "metadata": {
        "id": "qYnXVQpP7iLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "#random.seed(42)\n",
        "test_samples = []\n",
        "test_labels = []\n",
        "for sample, label in random.sample(list(test_data), k=9):\n",
        "  test_samples.append(sample)\n",
        "  test_labels.append(label)\n",
        "\n",
        "# View the first sample shape\n",
        "test_samples[0].shape"
      ],
      "metadata": {
        "id": "cm1acWdL9q6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(test_samples[0].squeeze(), cmap=\"gray\")\n",
        "plt.title(classes_names[test_labels[0]])"
      ],
      "metadata": {
        "id": "W0-S1jbe-b8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "pred_probs = make_predictions(model=model_2,\n",
        "                              data=test_samples)\n",
        "\n",
        "# View first two prediction probability\n",
        "pred_probs[:2]"
      ],
      "metadata": {
        "id": "AyzaxrQ1-syN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert prediction probabilities t labels\n",
        "pred_classes = pred_probs.argmax(dim=1)\n",
        "pred_classes"
      ],
      "metadata": {
        "id": "o4uL6rVQ_GF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels"
      ],
      "metadata": {
        "id": "FQ_ig0Ld_ZXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot predictions\n",
        "plt.figure(figsize=(9, 9))\n",
        "nrows = 3\n",
        "ncols = 3\n",
        "for i, sample in enumerate(test_samples):\n",
        "  # Create subplot\n",
        "  plt.subplot(nrows, ncols, i+1)\n",
        "\n",
        "  # Plot the target image\n",
        "  plt.imshow(sample.squeeze(), cmap=\"gray\")\n",
        "\n",
        "  # Find the prediction (in texxt form, e.g \"sandale\")\n",
        "  pred_label = classes_names[pred_classes[i]]\n",
        "\n",
        "  # Get the thruth label (in text form)\n",
        "  truth_label = classes_names[test_labels[i]]\n",
        "\n",
        "  # Create a title for the plot\n",
        "  title_text = f\"Pred: {pred_label} | Truth: {truth_label}\"\n",
        "\n",
        "  # Check for equality between pred and  and change color of title text\n",
        "  if pred_label == truth_label:\n",
        "    plt.title(title_text, fontsize=10, c=\"g\") # green text if prediction same as thruth\n",
        "  else:\n",
        "    plt.title(title_text, fontsize=10, c=\"r\")\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "kQaH2PJW_kFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Save and load the best performing model"
      ],
      "metadata": {
        "id": "Jg7qnY661y2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# create model directory path\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True,\n",
        "                 exist_ok=True)\n",
        "\n",
        "# Create model save\n",
        "MODEL_NAME = \"03_pytorch_computer_vision_model_2.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "# Save the model state dict\n",
        "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
        "torch.save(obj=model_2.state_dict(),\n",
        "           f=MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "id": "f3IpVP-Qtr-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new instance\n",
        "loaded_model = FashionMNISTModelV2(input_shape=1,\n",
        "                                   hidden_units=10,\n",
        "                                   output_shape=len(classes_names))\n",
        "\n",
        "# load in the save state_dict()\n",
        "loaded_model.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n",
        "\n",
        "# Load the model to the target device\n",
        "loaded_model.to(device)"
      ],
      "metadata": {
        "id": "jNgxlkXt2n0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate loaded model\n",
        "loaded_model_results = eval_model(\n",
        "    model=loaded_model,\n",
        "    data_loader=test_dataloader,\n",
        "    loss_fn=loss_fn,\n",
        "    accuracy_fn=accuracy_fn\n",
        ")\n",
        "\n",
        "loaded_model_results"
      ],
      "metadata": {
        "id": "BCGcpTFs3M9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_results"
      ],
      "metadata": {
        "id": "FOnTuHXR3jsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if model results are close to each other\n",
        "torch.isclose(torch.tensor(model_2_results[\"model_loss\"]),\n",
        "              torch.tensor(loaded_model_results[\"model_loss\"]))"
      ],
      "metadata": {
        "id": "pVt3vyvw3tTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Computer Vision Exercises"
      ],
      "metadata": {
        "id": "DX4Ro7_e5z8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the torchivision.datasets.MNIST() train and test datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "\n",
        "mnist_train_data = torchvision.datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "mnist_test_data = torchvision.datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n"
      ],
      "metadata": {
        "id": "gzLkYIeR5zdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualise 5 samples\n",
        "img, label = mnist_train_data[0]"
      ],
      "metadata": {
        "id": "IZZpl7GY5zZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image, label = mnist_train_data[0]\n",
        "print(f\"Image shape: {image.shape}\")\n",
        "plt.imshow(image.squeeze())\n",
        "plt.title(label);"
      ],
      "metadata": {
        "id": "Uy_QeSQN4Big"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn the MNIST train and test datasets into dataloaders\n",
        "mnist_train_dataloader = DataLoader(mnist_train_data, batch_size=32, shuffle=True)\n",
        "mnist_test_dataloader = DataLoader(mnist_test_data, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "9CkCF7rc7Ybm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "id": "e-8Eq2hv8Drt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = mnist_train_data.classes\n",
        "classes"
      ],
      "metadata": {
        "id": "KEvFzS448lKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(classes)"
      ],
      "metadata": {
        "id": "Evd91bxV9Qmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_to_idx = mnist_train_data.class_to_idx\n",
        "class_to_idx"
      ],
      "metadata": {
        "id": "I2ylh5Xv9FSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FashionMNISTModelV2(input_shape=1, hidden_units=10,output_shape=len(classes)).to(device)"
      ],
      "metadata": {
        "id": "_djiFdVq8FFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "F5wkVRSH9Ve9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.1)\n",
        "from helper_functions import accuracy_fn"
      ],
      "metadata": {
        "id": "Oap3uU979zjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "id": "UTqu4YklBuCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "train_time_start_on_gpu\n",
        "epochs = 3\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch}\\n----------------------------------\")\n",
        "  train_step(\n",
        "      model=model,\n",
        "      data_loader=mnist_train_dataloader,\n",
        "      loss_fn = loss_fn,\n",
        "      optimizer=optimizer,\n",
        "      accuracy_fn=accuracy_fn,\n",
        "      device=device\n",
        "  )\n",
        "  test_step(\n",
        "      model=model,\n",
        "      data_loader=mnist_test_dataloader,\n",
        "      loss_fn=loss_fn,\n",
        "      accuracy_fn=accuracy_fn,\n",
        "      device=device\n",
        "  )\n",
        "\n",
        "# Calculate training time\n",
        "train_time_end_on_gpu = timer()\n",
        "total_train_time_model_1 = print_train_time(start=train_time_start_on_gpu,\n",
        "                                            end=train_time_end_on_gpu,\n",
        "                                            device=str(next(model.parameters()).device))\n",
        "\n"
      ],
      "metadata": {
        "id": "YrHozoU59WXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_results = eval_model(model, mnist_test_dataloader, loss_fn, accuracy_fn)\n",
        "model_results"
      ],
      "metadata": {
        "id": "NxLAAEGcChEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "test_samples = []\n",
        "test_labels = []\n",
        "for sample, label in random.sample(list(mnist_test_data), k=5):\n",
        "  test_samples.append(sample)\n",
        "  test_labels.append(label)\n",
        "\n",
        "# View the first sample shape\n",
        "test_samples[0].shape"
      ],
      "metadata": {
        "id": "egDZLVyLCtIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_probs = make_predictions(model=model, data=test_samples)\n",
        "pred_classes = pred_probs.argmax(dim=1)\n",
        "pred_classes[0]"
      ],
      "metadata": {
        "id": "583h9b8UC1Iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot predictions\n",
        "plt.figure(figsize=(9, 9))\n",
        "nrows = 3\n",
        "ncols = 3\n",
        "for i, sample in enumerate(test_samples):\n",
        "  # Create subplot\n",
        "  plt.subplot(nrows, ncols, i+1)\n",
        "\n",
        "  # Plot the target image\n",
        "  plt.imshow(sample.squeeze(), cmap=\"gray\")\n",
        "\n",
        "  # Find the prediction (in texxt form, e.g \"sandale\")\n",
        "  pred_label = classes[pred_classes[i]]\n",
        "\n",
        "  # Get the thruth label (in text form)\n",
        "  truth_label = classes[test_labels[i]]\n",
        "\n",
        "  # Create a title for the plot\n",
        "  title_text = f\"Pred: {pred_label} | Truth: {truth_label}\"\n",
        "\n",
        "  # Check for equality between pred and  and change color of title text\n",
        "  if pred_label == truth_label:\n",
        "    plt.title(title_text, fontsize=10, c=\"g\") # green text if prediction same as thruth\n",
        "  else:\n",
        "    plt.title(title_text, fontsize=10, c=\"r\")\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "BJ-cmm0MDQd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L4DtvNgXDljH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}